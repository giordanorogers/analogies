{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using top all heads for experiment: [(33, 16), (14, 21), (27, 21), (35, 19), (34, 4), (30, 52), (39, 43), (34, 48), (33, 42), (33, 14), (35, 18), (28, 1), (34, 44), (27, 38), (49, 7), (28, 45), (35, 17), (34, 43), (27, 22), (31, 38), (31, 35), (16, 48), (20, 8), (38, 48), (32, 18), (28, 40), (29, 30), (35, 34), (30, 33), (30, 24), (24, 6), (33, 41), (2, 60), (5, 46), (27, 20), (18, 43), (33, 54), (25, 60), (37, 30), (28, 41), (38, 52), (26, 37), (32, 43), (39, 40), (49, 2), (33, 45), (31, 20), (28, 6), (24, 30), (54, 11), (31, 39), (18, 37), (8, 43), (30, 29), (28, 46), (32, 7), (15, 19), (15, 21), (17, 61), (6, 6), (4, 45), (28, 47), (30, 51), (33, 15), (21, 26), (19, 51), (22, 7), (32, 21), (33, 9), (11, 34), (16, 31), (26, 23), (31, 28), (31, 0), (12, 3), (22, 29), (1, 47), (34, 46), (24, 7), (23, 42)]\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import json\n",
        "import re\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import nnsight\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.auto import tqdm\n",
        "from transformers import AutoTokenizer\n",
        "import einops\n",
        "\n",
        "# --- Parameters ---\n",
        "MODEL_NAME = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
        "DATA_FILE = Path(\"../data/patching_dataset_N32_mixed.jsonl\") # From 100_patching_setup\n",
        "MAX_NEW_TOKENS = 6 # Max length for the answer\n",
        "\n",
        "# The heads identified in a previous experiment. We'll take the top 10.\n",
        "ANALOGY_HEADS = [(33, 16), (14, 21), (27, 21), (35, 19), (34, 4), (30, 52), (39, 43), (34, 48), (33, 42), (33, 14), (35, 18), (28, 1), (34, 44), (27, 38), (49, 7), (28, 45), (35, 17), (34, 43), (27, 22), (31, 38), (31, 35), (16, 48), (20, 8), (38, 48), (32, 18), (28, 40), (29, 30), (35, 34), (30, 33), (30, 24), (24, 6), (33, 41), (2, 60), (5, 46), (27, 20), (18, 43), (33, 54), (25, 60), (37, 30), (28, 41), (38, 52), (26, 37), (32, 43), (39, 40), (49, 2), (33, 45), (31, 20), (28, 6), (24, 30), (54, 11), (31, 39), (18, 37), (8, 43), (30, 29), (28, 46), (32, 7), (15, 19), (15, 21), (17, 61), (6, 6), (4, 45), (28, 47), (30, 51), (33, 15), (21, 26), (19, 51), (22, 7), (32, 21), (33, 9), (11, 34), (16, 31), (26, 23), (31, 28), (31, 0), (12, 3), (22, 29), (1, 47), (34, 46), (24, 7), (23, 42)]\n",
        "TOP_K_HEADS = 25\n",
        "CANDIDATE_HEADS = ANALOGY_HEADS\n",
        "\n",
        "print(f\"Using top all heads for experiment: {CANDIDATE_HEADS}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model and tokenizer loaded.\n"
          ]
        }
      ],
      "source": [
        "# Load the model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True, trust_remote_code=True)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = nnsight.LanguageModel(\n",
        "    MODEL_NAME,\n",
        "    tokenizer=tokenizer,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    attn_implementation=\"eager\"\n",
        ")\n",
        "\n",
        "# Get model dimensions\n",
        "D_MODEL = model.config.hidden_size\n",
        "N_HEADS = model.config.num_attention_heads\n",
        "N_LAYERS = model.config.num_hidden_layers\n",
        "D_HEAD = D_MODEL // N_HEADS\n",
        "\n",
        "print(\"Model and tokenizer loaded.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "def free_gpu_cache():\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "free_gpu_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 32 items from ../data/patching_dataset_N32_mixed.jsonl\n",
            "\n",
            "First example:\n",
            "{\n",
            "  \"story\": \"The feclur is made of placlugav. The artifact is crafted out of resin. The feclur is within the frifeslo. The artifact is within the library.\",\n",
            "  \"analogy\": \"artifact is to feclur as resin is to\",\n",
            "  \"answer\": \"placlugav\",\n",
            "  \"meta\": {\n",
            "    \"relation_target\": \"made of\",\n",
            "    \"relation_distractor_family\": \"located in\",\n",
            "    \"surface_r1_s1\": \"crafted out of\",\n",
            "    \"surface_r1_s2\": \"made of\",\n",
            "    \"surface_r2_s1\": \"within\",\n",
            "    \"surface_r2_s2\": \"within\",\n",
            "    \"lexicon_condition\": \"mixed\",\n",
            "    \"s1_noun_type\": \"real\",\n",
            "    \"s2_noun_type\": \"fake\",\n",
            "    \"seed\": 23,\n",
            "    \"template\": \"S1:S2::O1:?\",\n",
            "    \"task\": \"Task-5 (O\\u2192O across)\"\n",
            "  },\n",
            "  \"prompt_source\": \"Finish the analogy in one word.\\nThe feclur is made of placlugav. The artifact is crafted out of resin. The feclur is within the frifeslo. The artifact is within the library.\\n\\nartifact is to feclur as resin is to\",\n",
            "  \"prompt_base\": \"Finish the analogy in one word.\\nThe feclur is made of placlugav. The artifact is crafted out of resin. The feclur is within the frifeslo. The artifact is within the library.\\n\\nartifact is to feclur as library is to\",\n",
            "  \"token_indices\": {\n",
            "    \"s1_in_r1\": 21,\n",
            "    \"o1_in_r1\": 26,\n",
            "    \"s1_in_r2\": 40,\n",
            "    \"o3_in_r2\": 44,\n",
            "    \"s2_in_r1\": 11,\n",
            "    \"o2_in_r1\": 18,\n",
            "    \"s2_in_r2\": 31,\n",
            "    \"o4_in_r2\": 37,\n",
            "    \"s1_in_cue\": 46,\n",
            "    \"o1_in_cue\": 53,\n",
            "    \"s2_in_cue\": 51,\n",
            "    \"o2_in_cue\": -1,\n",
            "    \"analogy_site\": 55\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Load the frozen dataset\n",
        "def read_jsonl(path):\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        return [json.loads(line) for line in f]\n",
        "\n",
        "eval_items = read_jsonl(DATA_FILE)\n",
        "print(f\"Loaded {len(eval_items)} items from {DATA_FILE}\")\n",
        "\n",
        "# Let's look at the first example\n",
        "print(\"\\nFirst example:\")\n",
        "print(json.dumps(eval_items[0], indent=2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Helper functions for necessity and sufficiency experiments defined.\n"
          ]
        }
      ],
      "source": [
        "# --- Core Logic and Helper Functions ---\n",
        "\n",
        "def canonicalize(text: str) -> str:\n",
        "    \"\"\"Simple string cleaning for comparing model outputs.\"\"\"\n",
        "    return re.sub(r\"[\\s'\\\".,;:]+$\", \"\", text.strip().lower())\n",
        "\n",
        "def get_em1(prompt: str, gold_answer: str, intervention_fn=None) -> int:\n",
        "    \"\"\"\n",
        "    Runs a single forward pass and returns 1 if the top predicted next token\n",
        "    is an exact match, else 0.\n",
        "    \"\"\"\n",
        "    with model.trace(prompt, validate=False):\n",
        "        # If an intervention function is provided, call it.\n",
        "        if intervention_fn:\n",
        "            intervention_fn()\n",
        "        \n",
        "        # Get the logits for the final token position.\n",
        "        final_logits = model.output.logits[0, -1, :]\n",
        "        \n",
        "        # Get the token ID of the top prediction and save it.\n",
        "        predicted_token_id = torch.argmax(final_logits).save()\n",
        "\n",
        "    # After the trace, get the concrete value from the proxy.\n",
        "    prediction_id = predicted_token_id.item()\n",
        "    \n",
        "    # Decode the single predicted token.\n",
        "    prediction = tokenizer.decode(prediction_id, skip_special_tokens=True)\n",
        "    \n",
        "    return int(canonicalize(prediction) in canonicalize(gold_answer))\n",
        "\n",
        "def necessity_ablation_intervention(heads_to_ablate: list):\n",
        "    \"\"\"\n",
        "    This function is passed to `get_em1` to perform mean-ablation.\n",
        "    It's defined here and will be called by nnsight during the forward pass.\n",
        "    \"\"\"\n",
        "    for layer, head in heads_to_ablate:\n",
        "        attn_out_proxy = model.model.layers[layer].self_attn.o_proj.input[0]\n",
        "        reshaped_proxy = einops.rearrange(\n",
        "            attn_out_proxy, \"s (h d) -> s h d\", h=N_HEADS, d=D_HEAD\n",
        "        )\n",
        "        head_mean = reshaped_proxy[:, head, :].mean(dim=0, keepdim=True)\n",
        "        reshaped_proxy[:, head, :] = head_mean\n",
        "        model.model.layers[layer].self_attn.o_proj.input[0] = einops.rearrange(\n",
        "            reshaped_proxy, \"s h d -> s (h d)\"\n",
        "        )\n",
        "\n",
        "def sufficiency_patching_intervention(source_activations: dict, heads_to_patch: list):\n",
        "    \"\"\"\n",
        "    This function is passed to `get_em1` to perform patching.\n",
        "    It patches in the previously saved `source_activations`.\n",
        "    \"\"\"\n",
        "    for layer, head in heads_to_patch:\n",
        "        attn_out_proxy = model.model.layers[layer].self_attn.o_proj.input[0]\n",
        "        reshaped_proxy = einops.rearrange(\n",
        "            attn_out_proxy, \"s (h d) -> s h d\", h=N_HEADS, d=D_HEAD\n",
        "        )\n",
        "        source_head_activation = source_activations[(layer, head)]\n",
        "        reshaped_proxy[:, head, :] = source_head_activation\n",
        "        model.model.layers[layer].self_attn.o_proj.input[0] = einops.rearrange(\n",
        "            reshaped_proxy, \"s h d -> s (h d)\"\n",
        "        )\n",
        "\n",
        "print(\"Helper functions for necessity and sufficiency experiments defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running necessity experiment (targeted ablation)...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ce11b924e4345e99a5e7625c33217a6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Ablation Testing:   0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompt='Finish the analogy in one word.\\nThe feclur is made of placlugav. The artifact is crafted out of resin. The feclur is within the frifeslo. The artifact is within the library.\\n\\nartifact is to feclur as resin is to'\n",
            "gold_answer='placlugav'\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c75b566cfb4a40d89b3648daad3edf8e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "baseline_em1=1\n",
            "all_ablated_em1=1\n",
            "prompt='Finish the analogy in one word.\\nThe caceli is crafted out of nislof. The caceli is housed in the zatradre. The vase is situated in the school. The vase is constructed from marble.\\n\\ncaceli is to vase as nislof is to'\n",
            "gold_answer='marble'\n",
            "baseline_em1=1\n",
            "all_ablated_em1=0\n",
            "prompt='Finish the analogy in one word.\\nThe enitocod is inside the ehugori. The bottle is composed of oak. The bottle is housed in the school. The enitocod is made of prikucr.\\n\\nenitocod is to bottle as prikucr is to'\n",
            "gold_answer='oak'\n",
            "baseline_em1=1\n",
            "all_ablated_em1=0\n",
            "prompt='Finish the analogy in one word.\\nThe flispu is situated in the uzath. The vase is composed of glass. The flispu is constructed from oyicez. The vase is inside the mall.\\n\\nvase is to flispu as glass is to'\n",
            "gold_answer='oyicez'\n",
            "baseline_em1=0\n",
            "all_ablated_em1=0\n",
            "prompt='Finish the analogy in one word.\\nThe ubiskey is located in the grutre. The ubiskey is made of ploralel. The jar is constructed from oak. The jar is situated in the museum.\\n\\njar is to ubiskey as oak is to'\n",
            "gold_answer='ploralel'\n",
            "baseline_em1=0\n",
            "all_ablated_em1=0\n",
            "prompt='Finish the analogy in one word.\\nThe destapl is made of stasu. The destapl is within the cahaska. The jewelry is housed in the school. The jewelry is constructed from resin.\\n\\njewelry is to destapl as resin is to'\n",
            "gold_answer='stasu'\n",
            "baseline_em1=0\n",
            "all_ablated_em1=0\n",
            "prompt='Finish the analogy in one word.\\nThe mikobra is crafted out of oqoku. The statue is made of clay. The statue is set on the workbench. The mikobra is resting on the eslaw.\\n\\nstatue is to mikobra as clay is to'\n",
            "gold_answer='oqoku'\n",
            "baseline_em1=1\n",
            "all_ablated_em1=0\n",
            "prompt='Finish the analogy in one word.\\nThe eglucugle is constructed from gliteqa. The eglucugle is placed on the kufle. The kiosk is made of resin. The kiosk is set on the stand.\\n\\neglucugle is to kiosk as gliteqa is to'\n",
            "gold_answer='resin'\n",
            "baseline_em1=1\n",
            "all_ablated_em1=0\n",
            "prompt='Finish the analogy in one word.\\nThe imija is constructed from yeglubr. The bottle is crafted out of glass. The imija is situated in the treficl. The bottle is housed in the park.\\n\\nbottle is to imija as glass is to'\n",
            "gold_answer='yeglubr'\n",
            "baseline_em1=1\n",
            "all_ablated_em1=1\n",
            "prompt='Finish the analogy in one word.\\nThe kerux is composed of huyorih. The cup is set on the counter. The kerux is sitting on the trudagla. The cup is crafted out of bronze.\\n\\nkerux is to cup as huyorih is to'\n",
            "gold_answer='bronze'\n",
            "baseline_em1=1\n",
            "all_ablated_em1=1\n",
            "prompt='Finish the analogy in one word.\\nThe noclofla is perched on the procloslo. The kiosk is composed of resin. The noclofla is crafted out of ugladegu. The kiosk is sitting on the workbench.\\n\\nnoclofla is to kiosk as ugladegu is to'\n",
            "gold_answer='resin'\n",
            "baseline_em1=0\n",
            "all_ablated_em1=0\n",
            "prompt='Finish the analogy in one word.\\nThe sculpture is inside the park. The athuplutu is located in the spuguq. The sculpture is constructed from plastic. The athuplutu is crafted out of nepugropr.\\n\\nsculpture is to athuplutu as plastic is to'\n",
            "gold_answer='nepugropr'\n",
            "baseline_em1=1\n",
            "all_ablated_em1=0\n",
            "prompt='Finish the analogy in one word.\\nThe jespa is within the kicewoday. The cup is inside the hotel. The jespa is made of braspit. The cup is composed of glass.\\n\\njespa is to cup as braspit is to'\n",
            "gold_answer='glass'\n",
            "baseline_em1=1\n",
            "all_ablated_em1=0\n",
            "prompt='Finish the analogy in one word.\\nThe jewelry is sitting on the table. The opabiwi is made of kexew. The jewelry is crafted out of resin. The opabiwi is sitting on the saclemi.\\n\\njewelry is to opabiwi as resin is to'\n",
            "gold_answer='kexew'\n",
            "baseline_em1=1\n",
            "all_ablated_em1=0\n",
            "prompt='Finish the analogy in one word.\\nThe elegogrer is constructed from unineplic. The artifact is crafted out of glass. The elegogrer is set on the ocusaglaj. The artifact is set on the workbench.\\n\\nelegogrer is to artifact as unineplic is to'\n",
            "gold_answer='glass'\n",
            "baseline_em1=1\n",
            "all_ablated_em1=0\n",
            "prompt='Finish the analogy in one word.\\nThe bench is set on the counter. The bench is composed of glass. The cipibig is crafted out of oligruhar. The cipibig is sitting on the steflu.\\n\\ncipibig is to bench as oligruhar is to'\n",
            "gold_answer='glass'\n",
            "baseline_em1=1\n",
            "all_ablated_em1=0\n",
            "prompt='Finish the analogy in one word.\\nThe kiosk is crafted out of oak. The kiosk is housed in the library. The frececli is within the todustaju. The frececli is composed of bugul.\\n\\nkiosk is to frececli as oak is to'\n",
            "gold_answer='bugul'\n",
            "baseline_em1=0\n",
            "all_ablated_em1=0\n",
            "prompt='Finish the analogy in one word.\\nThe sculpture is constructed from clay. The prafiqi is crafted out of idriprewe. The prafiqi is located in the plapruz. The sculpture is located in the library.\\n\\nsculpture is to prafiqi as clay is to'\n",
            "gold_answer='idriprewe'\n",
            "baseline_em1=1\n",
            "all_ablated_em1=1\n",
            "prompt='Finish the analogy in one word.\\nThe zustob is housed in the piclafre. The jar is within the office. The zustob is composed of globrales. The jar is crafted out of bronze.\\n\\nzustob is to jar as globrales is to'\n",
            "gold_answer='bronze'\n",
            "baseline_em1=0\n",
            "all_ablated_em1=0\n",
            "prompt='Finish the analogy in one word.\\nThe bewugehef is crafted out of aplevast. The artifact is within the hotel. The bewugehef is housed in the frexi. The artifact is made of oak.\\n\\nbewugehef is to artifact as aplevast is to'\n",
            "gold_answer='oak'\n",
            "baseline_em1=1\n",
            "all_ablated_em1=0\n",
            "prompt='Finish the analogy in one word.\\nThe statue is made of steel. The mequwegr is crafted out of oqoki. The mequwegr is sitting on the fabay. The statue is set on the workbench.\\n\\nstatue is to mequwegr as steel is to'\n",
            "gold_answer='oqoki'\n",
            "baseline_em1=1\n",
            "all_ablated_em1=1\n",
            "prompt='Finish the analogy in one word.\\nThe plathed is housed in the ladafuhoy. The bottle is located in the office. The plathed is constructed from ibuna. The bottle is crafted out of clay.\\n\\nplathed is to bottle as ibuna is to'\n",
            "gold_answer='clay'\n",
            "baseline_em1=1\n",
            "all_ablated_em1=0\n",
            "prompt='Finish the analogy in one word.\\nThe ahedeqen is composed of slewopike. The ahedeqen is perched on the zonoruv. The jewelry is constructed from steel. The jewelry is perched on the pedestal.\\n\\nahedeqen is to jewelry as slewopike is to'\n",
            "gold_answer='steel'\n",
            "baseline_em1=1\n",
            "all_ablated_em1=1\n",
            "prompt='Finish the analogy in one word.\\nThe kiosk is resting on the stand. The kiosk is composed of steel. The trostast is crafted out of atugazil. The trostast is perched on the enodobamu.\\n\\nkiosk is to trostast as steel is to'\n",
            "gold_answer='atugazil'\n",
            "baseline_em1=0\n",
            "all_ablated_em1=0\n",
            "prompt='Finish the analogy in one word.\\nThe cup is housed in the hotel. The cralol is situated in the edricrar. The cup is constructed from steel. The cralol is composed of avumat.\\n\\ncup is to cralol as steel is to'\n",
            "gold_answer='avumat'\n",
            "baseline_em1=1\n",
            "all_ablated_em1=1\n",
            "prompt='Finish the analogy in one word.\\nThe fulihuth is within the oboplip. The cup is situated in the office. The fulihuth is crafted out of egranetiq. The cup is made of clay.\\n\\nfulihuth is to cup as egranetiq is to'\n",
            "gold_answer='clay'\n",
            "baseline_em1=0\n",
            "all_ablated_em1=0\n",
            "prompt='Finish the analogy in one word.\\nThe artifact is resting on the pedestal. The artifact is constructed from plastic. The mofeh is perched on the plaga. The mofeh is made of gurecig.\\n\\nartifact is to mofeh as plastic is to'\n",
            "gold_answer='gurecig'\n",
            "baseline_em1=0\n",
            "all_ablated_em1=0\n",
            "prompt='Finish the analogy in one word.\\nThe unucregre is inside the ihitrapif. The jewelry is housed in the library. The unucregre is composed of yinovase. The jewelry is constructed from oak.\\n\\njewelry is to unucregre as oak is to'\n",
            "gold_answer='yinovase'\n",
            "baseline_em1=1\n",
            "all_ablated_em1=0\n",
            "prompt='Finish the analogy in one word.\\nThe thimiceth is placed on the wapifl. The vase is crafted out of oak. The thimiceth is constructed from briyespa. The vase is sitting on the workbench.\\n\\nvase is to thimiceth as oak is to'\n",
            "gold_answer='briyespa'\n",
            "baseline_em1=0\n",
            "all_ablated_em1=1\n",
            "prompt='Finish the analogy in one word.\\nThe drivoni is composed of crovew. The statue is located in the office. The statue is constructed from resin. The drivoni is inside the thegoxofl.\\n\\ndrivoni is to statue as crovew is to'\n",
            "gold_answer='resin'\n",
            "baseline_em1=1\n",
            "all_ablated_em1=0\n",
            "prompt='Finish the analogy in one word.\\nThe huspeku is set on the ployez. The bottle is composed of bronze. The bottle is placed on the workbench. The huspeku is crafted out of iclegoxe.\\n\\nhuspeku is to bottle as iclegoxe is to'\n",
            "gold_answer='bronze'\n",
            "baseline_em1=1\n",
            "all_ablated_em1=0\n",
            "prompt='Finish the analogy in one word.\\nThe bench is crafted out of marble. The dutem is sitting on the razav. The dutem is constructed from satoco. The bench is placed on the counter.\\n\\ndutem is to bench as satoco is to'\n",
            "gold_answer='marble'\n",
            "baseline_em1=1\n",
            "all_ablated_em1=0\n",
            "Necessity experiment complete.\n"
          ]
        }
      ],
      "source": [
        "# --- Experiment 1: Necessity (Targeted Ablation) ---\n",
        "\n",
        "necessity_results = []\n",
        "dataset_subset = eval_items # Using the full dataset as specified\n",
        "\n",
        "print(\"Running necessity experiment (targeted ablation)...\")\n",
        "\n",
        "# Loop over each example in the dataset\n",
        "for ex_idx, ex in enumerate(tqdm(dataset_subset, desc=\"Ablation Testing\")):\n",
        "    prompt = ex['prompt_source'] # For necessity, we test on the correct prompt\n",
        "    print(f\"{prompt=}\")\n",
        "    gold_answer = ex['answer']\n",
        "    print(f\"{gold_answer=}\")\n",
        "    \n",
        "    # 1. Get baseline performance (no intervention)\n",
        "    baseline_em1 = get_em1(prompt, gold_answer)\n",
        "    print(f\"{baseline_em1=}\")\n",
        "    \n",
        "    # 2. Get performance when ablating the entire set of candidate heads\n",
        "    all_ablated_em1 = get_em1(\n",
        "        prompt, \n",
        "        gold_answer, \n",
        "        intervention_fn=lambda: necessity_ablation_intervention(CANDIDATE_HEADS)\n",
        "    )\n",
        "    print(f\"{all_ablated_em1=}\")\n",
        "    \n",
        "    # Store the result for the full set ablation\n",
        "    necessity_results.append({\n",
        "        \"ex_idx\": ex_idx,\n",
        "        \"head\": \"all_10\",\n",
        "        \"baseline_em1\": baseline_em1,\n",
        "        \"ablated_em1\": all_ablated_em1\n",
        "    })\n",
        "\n",
        "    # 3. Get performance when ablating each head individually\n",
        "    for layer, head in CANDIDATE_HEADS:\n",
        "        single_head_to_ablate = [(layer, head)]\n",
        "        \n",
        "        # The `h=single_head_to_ablate` trick ensures the lambda captures the correct head\n",
        "        single_ablated_em1 = get_em1(\n",
        "            prompt, \n",
        "            gold_answer, \n",
        "            intervention_fn=lambda h=single_head_to_ablate: necessity_ablation_intervention(h)\n",
        "        )\n",
        "        \n",
        "        necessity_results.append({\n",
        "            \"ex_idx\": ex_idx,\n",
        "            \"head\": f\"L{layer}H{head}\",\n",
        "            \"baseline_em1\": baseline_em1,\n",
        "            \"ablated_em1\": single_ablated_em1\n",
        "        })\n",
        "\n",
        "print(\"Necessity experiment complete.\")\n",
        "\n",
        "# Convert to a DataFrame for easier analysis\n",
        "df_necessity = pd.DataFrame(necessity_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline EM@1 Accuracy: 0.688\n",
            "After ablating top 25 heads: 0.250\n",
            "Accuracy Drop: 0.438 (63.6%)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 400x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# --- Analysis and Visualization ---\n",
        "\n",
        "# 1. Overall Effect of Ablating the Full Set\n",
        "df_all_ablated = df_necessity[df_necessity['head'] == 'all_10']\n",
        "baseline_acc = df_all_ablated['baseline_em1'].mean()\n",
        "full_ablation_acc = df_all_ablated['ablated_em1'].mean()\n",
        "acc_drop = baseline_acc - full_ablation_acc\n",
        "\n",
        "print(f\"Baseline EM@1 Accuracy: {baseline_acc:.3f}\")\n",
        "print(f\"After ablating top {TOP_K_HEADS} heads: {full_ablation_acc:.3f}\")\n",
        "print(f\"Accuracy Drop: {acc_drop:.3f} ({(acc_drop / baseline_acc) * 100:.1f}%)\")\n",
        "\n",
        "# Plot: Baseline vs. Ablated Set\n",
        "plt.figure(figsize=(4, 5))\n",
        "sns.barplot(x=['Baseline', f'Top {TOP_K_HEADS} Ablated'], y=[baseline_acc, full_ablation_acc])\n",
        "plt.title(f'Necessity: Ablating Top {TOP_K_HEADS} Heads')\n",
        "plt.ylabel('EM@1 Accuracy')\n",
        "plt.ylim(0, 1)\n",
        "plt.show()\n",
        "\n",
        "# # 2. Per-Head Ablation Effect\n",
        "# df_single_heads = df_necessity[df_necessity['head'] != 'all_10'].copy()\n",
        "# df_single_heads['em1_drop'] = df_single_heads['baseline_em1'] - df_single_heads['ablated_em1']\n",
        "# mean_drop_per_head = df_single_heads.groupby('head')['em1_drop'].mean().sort_values(ascending=False)\n",
        "# \n",
        "# # Plot: Per-head delta EM@1\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# mean_drop_per_head.plot(kind='bar')\n",
        "# plt.title('Individual Head Ablation: Mean Drop in EM@1')\n",
        "# plt.ylabel(' EM@1 (Drop in Accuracy)')\n",
        "# plt.xlabel('Head (Layer, Index)')\n",
        "# plt.xticks(rotation=45, ha='right')\n",
        "# plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n",
        "# \n",
        "# # 3. Cumulative Ablation Curve\n",
        "# # Note: This part re-runs the experiment and can be slow.\n",
        "# cumulative_results = []\n",
        "# sorted_heads = mean_drop_per_head.index.tolist()\n",
        "# \n",
        "# for k in range(1, len(sorted_heads) + 1):\n",
        "#     heads_to_ablate_k = [(int(h.split('H')[0][1:]), int(h.split('H')[1])) for h in sorted_heads[:k]]\n",
        "#     \n",
        "#     ablated_scores = []\n",
        "#     for ex in tqdm(eval_items, desc=f'Cumulative Ablating Top {k}', leave=False):\n",
        "#         score = get_em1(\n",
        "#             ex['prompt_source'], \n",
        "#             ex['answer'], \n",
        "#             intervention_fn=lambda h=heads_to_ablate_k: necessity_ablation_intervention(h)\n",
        "#         )\n",
        "#         ablated_scores.append(score)\n",
        "#     \n",
        "#     cumulative_results.append({'k': k, 'em1': np.mean(ablated_scores)})\n",
        "# \n",
        "# df_cumulative = pd.DataFrame(cumulative_results)\n",
        "# \n",
        "# # Plot: Cumulative Ablation\n",
        "# plt.figure(figsize=(8, 5))\n",
        "# plt.plot(df_cumulative['k'], df_cumulative['em1'], marker='o', linestyle='-')\n",
        "# plt.axhline(y=baseline_acc, color='r', linestyle='--', label=f'Baseline Acc ({baseline_acc:.3f})')\n",
        "# plt.axhline(y=full_ablation_acc, color='g', linestyle='--', label=f'Full Ablation Acc ({full_ablation_acc:.3f})')\n",
        "# plt.title('Cumulative Ablation of Top Heads')\n",
        "# plt.xlabel('Number of Top Heads Ablated (k)')\n",
        "# plt.ylabel('EM@1 Accuracy')\n",
        "# plt.xticks(range(1, len(sorted_heads) + 1))\n",
        "# plt.legend()\n",
        "# plt.grid(True, which='both', linestyle='--', alpha=0.7)\n",
        "# plt.ylim(0, 1)\n",
        "# plt.show()\n",
        "# \n",
        "# # 4. Sufficiency Results\n",
        "# base_acc_sufficiency = df_sufficiency['base_em1'].mean()\n",
        "# patched_acc_sufficiency = df_sufficiency['patched_em1'].mean()\n",
        "# acc_recovery = patched_acc_sufficiency - base_acc_sufficiency\n",
        "# \n",
        "# print(\"\\n--- Sufficiency Experiment Results ---\")\n",
        "# print(f\"Base (Corrupted) Prompt EM@1: {base_acc_sufficiency:.3f}\")\n",
        "# print(f\"After patching top 10 heads: {patched_acc_sufficiency:.3f}\")\n",
        "# print(f\"Accuracy Recovery: +{acc_recovery:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "retrieval2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
